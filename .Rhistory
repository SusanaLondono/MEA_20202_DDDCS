# Se cargan las librerías necesarias para el desarrollo del trabajo
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(readxl)
library(caret)
library("heatmaply")
library(datos)
library(tidyverse)
library(clusterSim)
library(lme4)
library(nlme)
library(ggplot2)
library(groupdata2)
library(knitr) # kable()
library(broom) #tidy()
library(hydroGOF) # rmse()
library(kableExtra)
library(ggpubr)
library(MLmetrics)
# La semilla aleatoria:
set.seed(20201018)
# Ruta para los diferentes usuarios:
pc_david <- "C:/Users/Carolina/Desktop/Base de datos.xlsx"
pc_su <- "C:/Users/sulon/OneDrive - Universidad EAFIT/MEA_actividad_evaluativa/curated/Base de datos.xlsx"
pc_valde ="D:/OneDrive - Grupo EPM/Diego_Valderrama/Personal/EAFIT/2020 - II/4. Métodos Estadisticos Avanzados/Trabajo Final/Base de datos.xlsx"
pc_jara <- "C:/Users/djaramiz/Universidad EAFIT/Susana Londoño Muñoz - MEA_actividad_evaluativa/curated/Base de datos.xlsx"
pc_cata<-"C:/Users/ASUS/Universidad EAFIT/Susana Londoño Muñoz - MEA_actividad_evaluativa/curated/Base de datos.xlsx"
# Se leen los datos:
bd_clean <- read_excel(pc_su,
col_types = c("text", "text", "text",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric"))
# La semilla aleatoria:
set.seed(20201018)
# Ruta para los diferentes usuarios:
pc_david <- "C:/Users/Carolina/Desktop/Base de datos.xlsx"
pc_su <- "C:/Users/sulon/OneDrive - Universidad EAFIT/MEA_actividad_evaluativa/curated/Base de datos.xlsx"
pc_valde <- "D:/OneDrive - Grupo EPM/Diego_Valderrama/Personal/EAFIT/2020 - II/4. Métodos Estadisticos Avanzados/Trabajo Final/Base de datos.xlsx"
pc_jara <- "C:/Users/djaramiz/Universidad EAFIT/Susana Londoño Muñoz - MEA_actividad_evaluativa/curated/Base de datos.xlsx"
pc_cata<-"C:/Users/ASUS/Universidad EAFIT/Susana Londoño Muñoz - MEA_actividad_evaluativa/curated/Base de datos.xlsx"
pc_ruta <- pc_jara
# Se leen los datos:
bd_clean <- read_excel(pc_ruta,
col_types = c("text", "text", "text",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric"))
#Diccionario de las variables
Nombre_Variable_base_de_datos <-c("Anio", "Nit", "Tot_CyG", "Tot_Ingresos", "PIB", "Cta_corr", "TRM", "T_interv", "T_Desemp", "Inflacion", "Bal_Fcal", "ICCV_var_tot", "ICCV_Mat", "ICCV_manobra", "ICCV_maq_eq", "ICCV_unifam", "ICCV_multifam", "IPP", "IPP_Mat", "IPVN_casa_nueva", "IPVN_tot_nal", "IPVU", "Cem_pro", "Cem_des", "Conc_pro", "PIB_CONS_ERNR", "VAR_PIB_CONS_ERNR", "Area_ap_viv", "Var_Area_ap_viv", "Unid_aprob", "Var_unid_aprob", "Var_IPVN")
Significado <-c("Año", "Nit", "Total Costos y Gastos", "Total Ingresos", "Producto Interno Bruto", "Cuenta corriente en Millones en USD", "Tasa Representativa del Mercado", "Tasa de Intervención", "Tasa de Desempleo", "Inflación", "Balance Fiscal Miles de Millones COP", "Índice de Costos de la Construcción de Vivienda Variación Total", "Índice de Costos de la Construcción de Vivienda Materiales", "Índice de Costos de la Construcción de Vivienda Mano de Obra", "Índice de Costos de la Construcción de Vivienda Maquinaria y Equipo", "Índice de Costos de la Construcción de Vivienda Unifamiliar", "Índice de Costos de la Construcción de Vivienda Multifamiliar", "Índice de Precios del Productor Total", "Índice de Precios del Productor Materiales", "Índice de Precios de Vivienda Casas", "Índice de Precios de Vivienda Nueva Total Nacional", "Índice de Precios de Vivienda Usada", "Cemento producido Toneladas", "Cemento despechado Toneladas", "Concreto producido Toneladas", "PIB actividad constructiva edificadora residencial y no residencial", "Variación PIB actividad constructiva edificadora residencial y no residencial", "Área aprobada de vivienda metros cuadrados", "Variación Área aprobada de vivienda metros cuadrados", "Unidades aprobadas", "Variación unidades aprobadas", "Variación Índice de Precios de Vivienda Nueva")
Diccionario <-data.frame(Nombre_Variable_base_de_datos, Significado)
Diccionario %>% kbl(row.names = FALSE) %>% kable_styling()
vars_me <- c("Anio", "PIB","Cta_corr","TRM","T_interv","T_Desemp","Inflacion", "Bal_Fcal", "ICCV_var_tot",
"ICCV_Mat", "ICCV_manobra", "ICCV_maq_eq","ICCV_unifam", "ICCV_multifam","IPP",
"IPP_Mat", "IPVN_ciudad", "IPVN_casa_nueva", "IPVN_tot_nal", "IPVU", "Cem_pro", "Cem_des",
"Conc_pro", "PIB_CONS_ERNR", "VAR_PIB_CONS_ERNR", "Area_ap_viv", "Var_Area_ap_viv",
"Unid_aprob", "Var_unid_aprob", "Var_IPVN")
df_var_me <- unique(bd_clean[,vars_me]) # Dataset de variables MACROECONOMICAS
df_vars <- bd_clean[ , -which(names(bd_clean) %in% vars_me)] # Dataset con variables de las empresas.
# "PIB","PIB_CONS_ERNR", "VAR_PIB_CONS_ERNR"
# "TRM","T_interv","T_Desemp","Inflacion",
#  "Bal_Fcal", "Cta_corr"
pib_pl <- ggplot(bd_clean) +
geom_point(aes(x = Anio, y = PIB)) +
ggtitle("PIB") +
ylab("Millones COP") + xlab("Año")
pibc_pl <- ggplot(bd_clean) +
geom_point(aes(x = Anio, y = PIB_CONS_ERNR)) +
ggtitle("PIB Construcción R y NR") +
ylab("Millones COP") + xlab("Año")
pibvc_pl <- ggplot(bd_clean) +
geom_point(aes(x = Anio, y = VAR_PIB_CONS_ERNR)) +
ggtitle("Variación PIB Cons. R y NR") +
ylab("%") + xlab("Año")
trm_pl <- ggplot(bd_clean) +
geom_point(aes(x = Anio, y = TRM))+
ggtitle("TRM") +
ylab("COP") + xlab("Año")
ti_pl <- ggplot(bd_clean) +
geom_point(aes(x = Anio, y = T_interv))+
ggtitle("Tasa intervención") +
ylab("%") + xlab("Año")
td_pl <- ggplot(bd_clean) +
geom_point(aes(x = Anio, y = T_Desemp))+
ggtitle("Tasa de desempleo") +
ylab("%") + xlab("Año")
i_pl <- ggplot(bd_clean) +
geom_point(aes(x = Anio, y = Inflacion))+
ggtitle("Inflación") +
ylab("%") + xlab("Año")
var_und_pl <- ggplot(bd_clean) +
geom_point(aes(x = Anio, y = Var_unid_aprob))+
ggtitle("Variación Unidades aprobadas") +
ylab("%") + xlab("Año")
cc_pl <- ggplot(bd_clean) +
geom_point(aes(x = Anio, y = Cta_corr)) +
ggtitle("Balance cuenta corriente") +
ylab("Millones de USD") + xlab("Año")
bf_pl <- ggplot(bd_clean) +
geom_point(aes(x = Anio, y = Bal_Fcal)) +
ggtitle("Balance Fiscal") +
ylab("Miles de Millones de COP") + xlab("Año")
ggarrange(pib_pl, pibc_pl, pibvc_pl,
labels = c("A", "B", "C", "D"),
ncol = 2, nrow = 2)
ggarrange(trm_pl, ti_pl, td_pl, i_pl,
labels = c("A", "B", "C", "D"),
ncol = 2, nrow = 2)
var_und_pl
ggarrange(cc_pl, bf_pl,
labels = c("A", "B", "C", "D"),
ncol = 2, nrow = 1)
#Creación de columna de factor para llevar a pesos constantes de 2019
bd_clean=mutate(bd_clean, factor1 = ifelse(Anio == 2019, 1,ifelse(Anio==2018, 1.0380,ifelse(Anio==2017,1.0710, 1.1148))))
#Aplicando un rezago de un año a la tasa de intervención
bd_clean=mutate(bd_clean, Tasai_Rez = ifelse(Anio == 2019, 0.0435,ifelse(Anio==2018, 0.0613,ifelse(Anio==2017,0.071, 0.0467))))
#Aplicando un rezago de un año a la tasa de desempleo
bd_clean=mutate(bd_clean, Tasad_Rez = ifelse(Anio == 2019, 0.0968,ifelse(Anio==2018, 0.0938,ifelse(Anio==2017,0.0922, 0.0893))))
#bd_clean <- data.frame(apply(bd_clean, 2, function(x) as.numeric(as.character(x))))
#Calculando variables a pesos constantes de 2019
bd_clean=mutate(bd_clean, TCyG_CTE=Tot_CyG*factor1,TIng_CTE=Tot_Ingresos*factor1,factor2=1.1789,PIB_CTE=factor2*PIB)
# Agregando el PIB Construcción de edificaciones residenciales y no residenciales
bd_clean=mutate(bd_clean, PIB_CONST = ifelse(Anio == 2019, 57509.4,ifelse(Anio==2018,58654,ifelse(Anio==2017,58907, 60125))))
bd_clean=mutate(bd_clean, factor3=1.1789,PIB_CONST_CTE=factor3*PIB_CONST)
hist(bd_clean$TCyG_CTE, main  = "Total Costos y Gastos",
xlab = "Total costos y gastos", ylab = "Frecuencia", las = 1)
CV<-sd(bd_clean$TCyG_CTE)/mean(bd_clean$TCyG_CTE)*100
CV
bd_clean$TCyG_CTE <- as.integer(bd_clean$TCyG_CTE)
bd_clean$TIng_CTE <- as.integer(bd_clean$TIng_CTE)
# Quitar TCyG_CTE y TIng_CTE = 0
bd_clean <- bd_clean[bd_clean$TCyG_CTE != 0,]
bd_clean <- bd_clean[bd_clean$TIng_CTE != 0,]
#summary(bd_clean$TCyG_CTE)
bd_clean <- transform(bd_clean, CSI_CTE = TCyG_CTE / TIng_CTE)
bp <- boxplot((bd_clean$CSI_CTE), las= 1, main = c("Costos sobre ingresos (CS)", "Con outliers"))
print('estadisticas del Boxplot')
bp$stats
# Se retiran los valores que están por fuera de los bigotes del boxplot anterior.
bd_clean<-mutate(bd_clean, IndexOut=(bd_clean$CSI_CTE>=bp$stats[1] & bd_clean$CSI_CTE<=bp$stats[5]))
bd_clean<-bd_clean[bd_clean$IndexOut!="FALSE",]
boxplot((bd_clean$CSI_CTE), las= 1, main = c("Costos sobre ingresos", "Sin valores extremos"))
par(mfrow=c(1,2))
hist(bd_clean$TCyG_CTE, main  = "Total Costos y Gastos",
xlab = "Total costos y gastos", ylab = "Frecuencia", las = 1)
hist(bd_clean$CSI_CTE, main  = "Costos totales sobre ingresos (CSI)",
xlab = "Costos totales sobre ingresos (CSI)", ylab = "Frecuencia", las = 1)
CV<-sd(bd_clean$CSI_CTE)/mean(bd_clean$CSI_CTE)*100
CV
summary(bd_clean$CSI_CTE)
cols_to_keep <- c("Anio","Nit","CIIU","Cta_corr","TRM","T_interv","T_Desemp",
"Inflacion","Bal_Fcal","ICCV_var_tot","ICCV_Mat", "ICCV_manobra",
"ICCV_maq_eq", "ICCV_unifam", "ICCV_multifam", "IPP", "IPP_Mat",
"IPVN_ciudad", "IPVN_casa_nueva", "IPVN_tot_nal", "IPVU",
"PIB_CONS_ERNR", "VAR_PIB_CONS_ERNR", "Var_Area_ap_viv",
"Unid_aprob", "Var_unid_aprob", "Var_IPVN", "Tasai_Rez",
"Tasad_Rez", "TCyG_CTE", "TIng_CTE", "PIB_CTE", "PIB_CONST",
"PIB_CONST_CTE", "CSI_CTE")
bd_clean <- bd_clean[, cols_to_keep]
#Categorización de las empresas según cuartiles de CSI
nit_csi <- bd_clean[,c('Nit', 'CSI_CTE')]
media <- aggregate(. ~ Nit, data=nit_csi, mean)
colnames(media)[2] <- "PromCSI_CTE"
media <- mutate(media, Cat_prom_CSI = ifelse(media$PromCSI_CTE <= quantile(media$PromCSI_CTE, 0.25, na.rm = FALSE), '1',ifelse(media$PromCSI_CTE <= quantile(media$PromCSI_CTE, 0.50, na.rm = FALSE),'2', ifelse(media$PromCSI_CTE <= quantile(media$PromCSI_CTE, 0.75, na.rm = FALSE),'3','4'))))
bd_clean <- (merge(media, bd_clean, by = 'Nit'))
#Media de CSI
d_byCat = na.omit(bd_clean) %>%
group_by(Cat_prom_CSI, Anio) %>%
summarise(CSI_CTE = mean(CSI_CTE))
ggplot(d_byCat, aes(x=Anio, y=CSI_CTE,
colour=Cat_prom_CSI, group=Cat_prom_CSI)) +
geom_line(size=1) + geom_point(size=3, shape=21, fill="white") +
ggtitle("Gráfica de interacción") +
labs(x= "Año", y="CSI")
boxplot((bd_clean$CSI_CTE~bd_clean$Anio), las= 1, main = c("Costos sobre ingresos por año"), ylab = "CSI", xlab = "Año")
# Se eliminan las empresas que no tienen información para los cuatro años.
muestra<-bd_clean
datos_agrup_nit <- bd_clean %>% count(bd_clean$Nit)
nits_todos_annos <- datos_agrup_nit[datos_agrup_nit$n == 4,]
solo_nits <- nits_todos_annos$`bd_clean$Nit`
muestra <- bd_clean[bd_clean$Nit %in% solo_nits,]
# Ordenamiento del dataset en año (Ascendet) y Nit(Descendente)
muestra <- muestra[order(muestra$Anio, decreasing = FALSE),] # Ordenar Año
muestra <- muestra[order(muestra$Nit, decreasing = TRUE),] # Ordenar por Nit
# Grafica de variacion de costos por años en puntos
ni<-4
G <- length(muestra$Nit)/ni
grupo <- factor(rep(x=1:G, each=ni))
ggplot(data = muestra, # Tome los primeros 120 registros -> aprox. 30 nits.
aes(x = as.factor(Anio) , y = CSI_CTE, color = grupo)) + geom_point() + theme_bw() + facet_wrap(~ Nit) +
theme(legend.position = "none") +
labs(title = "Muestra CSI")+
xlab("Años") +
ylab("Costos")
# Se ponen las variables Nit y Cat_prom_CSI como tipo factor
bd_clean$Nit <- as.factor(bd_clean$Nit)
bd_clean$Cat_prom_CSI <- as.factor(bd_clean$Cat_prom_CSI)
# Se parten los datos en 15% de test y 85% de entrenamiento.
parts <- partition(bd_clean, p = 0.15, id_col = "Nit", cat_col = 'Cat_prom_CSI')
test_set <- parts[[1]]
train_set <- parts[[2]]
test_set
# se agrega una columna con un número de 1 a k que será al grupo que pertenece
# para hacer la validación cruzada.
train_set <- fold(train_set, k = 4, cat_col = 'Cat_prom_CSI', id_col = 'Nit')
# Organizar por folds.
train_set <- train_set %>% arrange(.folds)
train_set
train_set %>%
count(Cat_prom_CSI)
crossvalidate <- function(data, k, model, dependent, random = FALSE){
# 'data' is the training set with the ".folds" column
# 'k' is the number of folds we have
# 'model' is a string describing a linear regression model formula
# 'dependent' is a string with the name of the score column we want to predict
# 'random' is a logical; do we have random effects in the model?
# Initialize empty list for recording performances
performances <- c()
# One iteration per fold
for (fold in 1:k){
# Create training set for this iteration
# Subset all the datapoints where .folds does not match the current fold
training_set <- data[data$.folds != fold,]
# Create test set for this iteration
# Subset all the datapoints where .folds matches the current fold
testing_set <- data[data$.folds == fold,]
## Train model
# If there is a random effect,
# use lmer() to train model
# else use lm()
if (isTRUE(random)){
# Train linear mixed effects model on training set
model <- lmer(model, training_set, REML=FALSE)
} else {
# Train linear model on training set
model <- lm(model, training_set)
}
## Test model
# Predict the dependent variable in the testing_set with the trained model
predicted <- predict(model, testing_set, allow.new.levels=TRUE)
# Get the Root Mean Square Error between the predicted and the observed
MSE <- mse(predicted, testing_set[[dependent]])
# Add the RMSE to the performance list
performances[fold] <- MSE
}
# Return the mean of the recorded RMSEs
return(c('MSE' = mean(performances)))
}
# Se definieron los siguientes modelos:
m0 <- 'CSI_CTE ~ (1 | Nit)'
m1 <- 'CSI_CTE ~ Var_unid_aprob+VAR_PIB_CONS_ERNR+(1|Nit)'
m2 <- 'CSI_CTE ~ Tasad_Rez+(1|Nit)'
m3 <- 'CSI_CTE ~ Var_unid_aprob+(1|Nit)'
m4 <- 'CSI_CTE ~ Tasad_Rez+VAR_PIB_CONS_ERNR+(1|Nit)'
m5 <- 'CSI_CTE ~ VAR_PIB_CONS_ERNR+Cat_prom_CSI+(Anio|Cat_prom_CSI)'
# Se creó un dataframe para que contenga el resumen de los modelos:
model_summary <-data.frame(modelo=character(0), formula=character(0), mse_valcruz=double(0), r2m_ent= double(0), r2c_ent = double(0), mse_po = double(0), aic= double(0))
nombre_cols <- c("Modelo", "Formula", "MSE_validacion_cruzada","r2m_ent", "r2c_ent" , "mse_pred_obs", "AIC")
print("Modelo solo con intercepto")
m0
r0 <- crossvalidate(train_set, k=4, model=m0, dependent='CSI_CTE', random=TRUE)
r0
res0 = lmer(m0, data = train_set)
summary(res0)
# R2
r20 <- MuMIn::r.squaredGLMM(res0)
# AIC
aic0 <- AIC(res0)
# Predicción y MSE
pred0 <-  predict(res0, test_set, allow.new.levels=TRUE)
MSE_po0 <- mse(pred0, test_set[['CSI_CTE']])
m0_sum <- data.frame("Modelo 0", m0, r0, round(r20[1],3),round(r20[2],3), round(MSE_po0, 3), round(aic0,3))
names(m0_sum) <- nombre_cols
model_summary <- rbind(model_summary, m0_sum)
model_summary %>%
kbl(row.names = FALSE) %>%
kable_styling()
print("M1")
m1
r1 <- crossvalidate(train_set, k=4, model=m1, dependent='CSI_CTE', random=TRUE)
r1
res1 = lmer(m1, data = train_set)
summary(res1)
r21 <- MuMIn::r.squaredGLMM(res1)
aic1 <- AIC(res1)
pred1 <-  predict(res1, test_set, allow.new.levels=TRUE)
# Get the Root Mean Square Error between the predicted and the observed
MSE_po1 <- mse(pred1, test_set[['CSI_CTE']])
m1_sum <- data.frame("Modelo 1", m1, r1, r21[1], r21[2], MSE_po1, aic1)
#Naming the Data Frame - Step 2
#"modelo", "formula", "mse_valcruz", "r2_entrenamiento" , "mse_po", "aic")
names(m1_sum) <-nombre_cols
#Using rbind() function to insert above observation
model_summary <- rbind(model_summary, m1_sum)
model_summary %>%
kbl(row.names = FALSE) %>%
kable_styling()
print("M2")
m2
r2 <- crossvalidate(train_set, k=4, model=m2, dependent='CSI_CTE', random=TRUE)
r2
res2 = lmer(m2, data = train_set)
summary(res2)
r22 <- MuMIn::r.squaredGLMM(res2)
aic2 <- AIC(res2)
pred2 <-  predict(res2, test_set, allow.new.levels=TRUE)
# Get the Root Mean Square Error between the predicted and the observed
MSE_po2 <- mse(pred2, test_set[['CSI_CTE']])
m2_sum <- data.frame("Modelo 2", m2, r2,r22[1], r22[2], MSE_po2, aic2)
#Naming the Data Frame - Step 2
#"modelo", "formula", "mse_valcruz", "r2_entrenamiento" , "mse_po", "aic")
names(m2_sum) <- nombre_cols
#Using rbind() function to insert above observation
model_summary <- rbind(model_summary, m2_sum)
model_summary %>%
kbl(row.names = FALSE) %>%
kable_styling()
print("Modelo 3")
m3
r3 <- crossvalidate(train_set, k=4, model=m3, dependent='CSI_CTE', random=TRUE)
r3
res3 = lmer(m3, data = train_set)
summary(res3)
r23 <- MuMIn::r.squaredGLMM(res3)
aic3 <- AIC(res3)
pred3 <-  predict(res3, test_set, allow.new.levels=TRUE)
# Get the Root Mean Square Error between the predicted and the observed
MSE_po3 <- mse(pred3, test_set[['CSI_CTE']])
m3_sum <- data.frame("Modelo 3", m3, r3,r23[1], r23[2], MSE_po3, aic3)
#Naming the Data Frame - Step 2
#"modelo", "formula", "mse_valcruz", "r2_entrenamiento" , "mse_po", "aic")
names(m3_sum) <- nombre_cols
#Using rbind() function to insert above observation
model_summary <- rbind(model_summary, m3_sum)
model_summary %>%
kbl(row.names = FALSE) %>%
kable_styling()
print("M4")
m4
r4 <- crossvalidate(train_set, k=4, model=m4, dependent='CSI_CTE', random=TRUE)
r4
res4 = lmer(m4, data = train_set)
summary(res4)
r24 <- MuMIn::r.squaredGLMM(res4)
aic4 <- AIC(res4)
pred4 <-  predict(res4, test_set, allow.new.levels=TRUE)
# Get the Root Mean Square Error between the predicted and the observed
MSE_po4 <- mse(pred4, test_set[['CSI_CTE']])
#Data Frame - Step 1
m4_sum <- data.frame("Modelo 4", m4, r4,r24[1], r24[2], MSE_po4, aic4)
#Naming the Data Frame - Step 2
#"modelo", "formula", "mse_valcruz", "r2_entrenamiento" , "mse_po", "aic")
names(m4_sum) <- nombre_cols
# Using rbind() function to insert above observation
model_summary <- rbind(model_summary, m4_sum)
model_summary %>%
kbl(row.names = FALSE) %>%
kable_styling()
print("M5")
m5
r5 <- crossvalidate(train_set, k=4, model=m5, dependent='CSI_CTE', random=TRUE)
r5
res5 = lmer(m5, data = train_set)
summary(res5)
r25 <- MuMIn::r.squaredGLMM(res5)
aic5 <- AIC(res5)
pred5 <-  predict(res5, test_set, allow.new.levels=TRUE)
# Get the Root Mean Square Error between the predicted and the observed
MSE_po5 <- mse(pred5, test_set[['CSI_CTE']])
#Data Frame - Step 1
m5_sum <- data.frame("Modelo 5", m5, r5, r25[1], r25[2], MSE_po5, aic5)
#Naming the Data Frame - Step 2
#"modelo", "formula", "mse_valcruz", "r2_entrenamiento" , "mse_po", "aic")
names(m5_sum) <- nombre_cols
# Using rbind() function to insert above observation
model_summary <- rbind(model_summary, m5_sum)
model_summary %>%
kbl(row.names = FALSE) %>%
kable_styling()
obs <- test_set$CSI_CTE
#Grafica de reales versus observados con el modelo 2
m2 <- ggplot() +                    # basic graphical object
geom_point(aes(x=obs, y=pred2), colour="red")+
ggtitle("Predicho vs Observado (M2)")+xlab("Observado") + ylab("Predicho") +
xlim(0.75,1.05) + ylim(0.75,1.05)+
geom_abline(slope=1, intercept=0)
#Grafica de reales versus observados con el modelo 5
m5 <- ggplot() +                    # basic graphical object
geom_point(aes(x=obs, y=pred5), colour="red")+
ggtitle("Predicho vs Observado (M5)")+xlab("Observado") + ylab("Predicho") +
xlim(0.75,1.05) + ylim(0.75,1.05)+
geom_abline(slope=1, intercept=0)
ggarrange(m2, m5,
labels = c("A", "B"),
ncol = 2, nrow = 1)
anova(res2,res0, refit=FALSE)
anova(res5,res0, refit=FALSE)
MAPE(pred2,obs)
MAPE(pred5,obs)
